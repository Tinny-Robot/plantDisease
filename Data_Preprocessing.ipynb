{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnrVgxCh8yidPPg7UIpXkB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Download Data"
      ],
      "metadata": {
        "id": "ta4gCKZn8ExN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 'https://drive.google.com/uc?id=Gknhsbdfyus'\n",
        "\n",
        "!unzip plantvillage.zip -d PlantVillage\n"
      ],
      "metadata": {
        "id": "Wu5itYzdAJea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the Data into Train, Validation, and Test"
      ],
      "metadata": {
        "id": "rt7K7oAx8Qco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# Set paths\n",
        "dataset_dir = Path(\"PlantVillage/PlantVillage\")\n",
        "output_base = Path(\"PlantVillage_Split\")\n",
        "train_dir = output_base / \"train\"\n",
        "val_dir = output_base / \"val\"\n",
        "test_dir = output_base / \"test\"\n",
        "\n",
        "# Create output dirs\n",
        "for split_dir in [train_dir, val_dir, test_dir]:\n",
        "    split_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Split ratios\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Process each class folder\n",
        "for class_dir in dataset_dir.iterdir():\n",
        "    if class_dir.is_dir():\n",
        "        images = list(class_dir.glob(\"*.jpg\"))\n",
        "        random.shuffle(images)\n",
        "        n = len(images)\n",
        "        n_train = int(n * train_ratio)\n",
        "        n_val = int(n * val_ratio)\n",
        "        n_test = n - n_train - n_val\n",
        "\n",
        "        split_data = {\n",
        "            train_dir / class_dir.name: images[:n_train],\n",
        "            val_dir / class_dir.name: images[n_train:n_train+n_val],\n",
        "            test_dir / class_dir.name: images[n_train+n_val:]\n",
        "        }\n",
        "\n",
        "        for split_path, image_list in split_data.items():\n",
        "            split_path.mkdir(parents=True, exist_ok=True)\n",
        "            for img_path in image_list:\n",
        "                shutil.copy(img_path, split_path / img_path.name)\n",
        "\n"
      ],
      "metadata": {
        "id": "GAY4Mvw48S5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "E_gr5ff6-1Zw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Sdf70kdNB92"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "# Define paths to raw dataset (replace with actual paths)\n",
        "train_dir = 'PlantVillage_Split/train'\n",
        "val_dir = 'PlantVillage_Split/val'\n",
        "test_dir = 'PlantVillage_Split/test'\n",
        "\n",
        "# Image preprocessing (resizing, normalization)\n",
        "def preprocess_image(image, target_size=(224, 224)):\n",
        "    image = tf.image.resize(image, target_size)\n",
        "    image = tf.keras.applications.efficientnet.preprocess_input(image)  # Normalize for EfficientNet\n",
        "    return image\n",
        "\n",
        "# Load and preprocess datasets\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_image)\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_image)\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_image)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=(224, 224), batch_size=50, class_mode='categorical')\n",
        "val_data = val_datagen.flow_from_directory(\n",
        "    val_dir, target_size=(224, 224), batch_size=50, class_mode='categorical')\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_dir, target_size=(224, 224), batch_size=50, class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Data Augmentation"
      ],
      "metadata": {
        "id": "07R81vuv-xIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation configuration (applied only to training data)\n",
        "augmentation = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    preprocessing_function=preprocess_image  # Ensure augmentation respects EfficientNet norms\n",
        ")\n",
        "\n",
        "augmented_train_data = augmentation.flow_from_directory(\n",
        "    train_dir, target_size=(224, 224), batch_size=50, class_mode='categorical')"
      ],
      "metadata": {
        "id": "Ev0nOZw_-xtm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}