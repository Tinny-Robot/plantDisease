{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6n/5QOogzJplqPnscr8i1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWmHTctHA91i"
      },
      "outputs": [],
      "source": [
        "#@title Initial Setup and Data Preparation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG19, InceptionV3, ResNet50, DenseNet201, EfficientNetV2B1\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 50\n",
        "EPOCHS = 50\n",
        "LR = 0.001\n",
        "CLASSES = 11\n",
        "\n",
        "# Data generators\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    'train_data',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_data = train_datagen.flow_from_directory(\n",
        "    'train_data',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
        ")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    'test_data',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Training Function\n",
        "def train_and_evaluate(model, model_name):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training {model_name} Model\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=5, restore_best_weights=True),\n",
        "        ModelCheckpoint(f'{model_name}_best.h5', save_best_only=True)\n",
        "    ]\n",
        "\n",
        "    # Train\n",
        "    history = model.fit(\n",
        "        train_data,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_data,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluation\n",
        "    print(\"\\nEvaluating on Test Set...\")\n",
        "    test_results = model.evaluate(test_data, verbose=0)\n",
        "\n",
        "    # Metrics\n",
        "    print(f\"\\nTest Accuracy: {test_results[1]*100:.2f}%\")\n",
        "    print(f\"Test Loss: {test_results[0]:.4f}\")\n",
        "    print(f\"Precision: {test_results[2]:.4f}\")\n",
        "    print(f\"Recall: {test_results[3]:.4f}\")\n",
        "\n",
        "    # Classification Report\n",
        "    y_pred = model.predict(test_data)\n",
        "    y_true = test_data.classes\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred_classes, target_names=list(test_data.class_indices.keys())))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    plt.figure(figsize=(12,10))\n",
        "    cm = confusion_matrix(y_true, y_pred_classes)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=test_data.class_indices.keys(),\n",
        "                yticklabels=test_data.class_indices.keys())\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    # Training History Plots\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title(f'{model_name} Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title(f'{model_name} Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return test_results"
      ],
      "metadata": {
        "id": "381Ju1aTCAHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title VGG-19 Model Training and Evaluation\n",
        "def build_vgg19():\n",
        "    base = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "    for layer in base.layers[:-4]:  # Freeze all but last 4 layers\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    predictions = Dense(CLASSES, activation='softmax')(x)\n",
        "    model = Model(inputs=base.input, outputs=predictions)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=LR),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', Precision(), Recall()]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "vgg19_model = build_vgg19()\n",
        "vgg19_results = train_and_evaluate(vgg19_model, \"VGG-19\")"
      ],
      "metadata": {
        "id": "81FfeJCKCGl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GoogleNet (InceptionV3) Model Training and Evaluation\n",
        "def build_googlenet():\n",
        "    base = InceptionV3(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "    for layer in base.layers[:-10]:  # Freeze all but last 10 layers\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    predictions = Dense(CLASSES, activation='softmax')(x)\n",
        "    model = Model(inputs=base.input, outputs=predictions)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=LR*0.5),  # Lower LR for Inception\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', Precision(), Recall()]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "googlenet_model = build_googlenet()\n",
        "googlenet_results = train_and_evaluate(googlenet_model, \"GoogleNet (InceptionV3)\")"
      ],
      "metadata": {
        "id": "jh15ziUOCHtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ResNet50 Model Training and Evaluation\n",
        "def build_resnet50():\n",
        "    base = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "    for layer in base.layers[:-15]:  # Freeze all but last 15 layers\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    predictions = Dense(CLASSES, activation='softmax')(x)\n",
        "    model = Model(inputs=base.input, outputs=predictions)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=LR),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', Precision(), Recall()]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "resnet50_model = build_resnet50()\n",
        "resnet50_results = train_and_evaluate(resnet50_model, \"ResNet50\")"
      ],
      "metadata": {
        "id": "J5MV47_JCNPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DenseNet201 Model Training and Evaluation\n",
        "def build_densenet():\n",
        "    base = DenseNet201(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "    for layer in base.layers[:-20]:  # Freeze all but last 20 layers\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    predictions = Dense(CLASSES, activation='softmax')(x)\n",
        "    model = Model(inputs=base.input, outputs=predictions)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=LR*0.7),  # Adjust LR for DenseNet\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', Precision(), Recall()]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "densenet_model = build_densenet()\n",
        "densenet_results = train_and_evaluate(densenet_model, \"DenseNet201\")"
      ],
      "metadata": {
        "id": "G-P7ZECJCQFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title EfficientNetV2-B1 Model Training and Evaluation\n",
        "def build_efficientnet():\n",
        "    base = EfficientNetV2B1(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "    for layer in base.layers[:-5]:  # Freeze all but last 5 layers\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    predictions = Dense(CLASSES, activation='softmax')(x)\n",
        "    model = Model(inputs=base.input, outputs=predictions)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=LR*1.2),  # Slightly higher LR\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', Precision(), Recall()]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "efficientnet_model = build_efficientnet()\n",
        "efficientnet_results = train_and_evaluate(efficientnet_model, \"EfficientNetV2-B1\")"
      ],
      "metadata": {
        "id": "oNPS7gTiCVTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Final Model Comparison\n",
        "print(\"\\n\\n=== Final Model Comparison ===\")\n",
        "results = {\n",
        "    'Model': ['VGG19', 'GoogleNet', 'ResNet50', 'DenseNet201', 'EfficientNetV2-B1'],\n",
        "    'Test Accuracy': [vgg19_results[1], googlenet_results[1], resnet50_results[1],\n",
        "                     densenet_results[1], efficientnet_results[1]],\n",
        "    'Test Loss': [vgg19_results[0], googlenet_results[0], resnet50_results[0],\n",
        "                 densenet_results[0], efficientnet_results[0]],\n",
        "    'Precision': [vgg19_results[2], googlenet_results[2], resnet50_results[2],\n",
        "                 densenet_results[2], efficientnet_results[2]],\n",
        "    'Recall': [vgg19_results[3], googlenet_results[3], resnet50_results[3],\n",
        "              densenet_results[3], efficientnet_results[3]]\n",
        "}\n",
        "\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n",
        "\n",
        "# Visual comparison\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "sns.barplot(x='Model', y='Test Accuracy', data=results_df)\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.barplot(x='Model', y='Test Loss', data=results_df)\n",
        "plt.title('Model Loss Comparison')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YNx0jOOrCXtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation (Post Training)"
      ],
      "metadata": {
        "id": "6jOAyLT2FBAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Evaluation Pipeline for All 5 Baseline Models\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, f1_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "def evaluate_all_models(models_dict, test_data):\n",
        "    \"\"\"\n",
        "    Evaluates multiple models and generates comparative reports\n",
        "    Args:\n",
        "        models_dict: Dictionary of {'model_name': loaded_model}\n",
        "        test_data: Test data generator (shuffle=False)\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    class_names = list(test_data.class_indices.keys())\n",
        "\n",
        "    for name, model in models_dict.items():\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Evaluating {name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Get predictions\n",
        "        y_true = test_data.classes\n",
        "        y_pred = model.predict(test_data)\n",
        "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "        # Classification Report\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_true, y_pred_classes, target_names=class_names, digits=4))\n",
        "\n",
        "        # Confusion Matrix\n",
        "        plt.figure(figsize=(12,10))\n",
        "        cm = confusion_matrix(y_true, y_pred_classes)\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=class_names,\n",
        "                    yticklabels=class_names)\n",
        "        plt.title(f'{name} Confusion Matrix', fontsize=14)\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.show()\n",
        "\n",
        "        # Store metrics\n",
        "        f1_per_class = f1_score(y_true, y_pred_classes, average=None)\n",
        "        macro_f1 = f1_score(y_true, y_pred_classes, average='macro')\n",
        "        macro_precision = precision_score(y_true, y_pred_classes, average='macro')\n",
        "        macro_recall = recall_score(y_true, y_pred_classes, average='macro')\n",
        "\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Macro Precision': macro_precision,\n",
        "            'Macro Recall': macro_recall,\n",
        "            'Macro F1': macro_f1,\n",
        "            'Worst Class': class_names[np.argmin(f1_per_class)],\n",
        "            'Worst F1': np.min(f1_per_class)\n",
        "        })\n",
        "\n",
        "        # F1-Score Distribution\n",
        "        plt.figure(figsize=(10,6))\n",
        "        sns.barplot(x=f1_per_class, y=class_names, palette='viridis')\n",
        "        plt.title(f'{name} F1-Scores by Class')\n",
        "        plt.xlim(0, 1)\n",
        "        plt.show()\n",
        "\n",
        "    # Comparative Analysis\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Comparative Performance Analysis\")\n",
        "    print(\"=\"*60)\n",
        "    print(results_df.sort_values('Macro F1', ascending=False).to_string(index=False))\n",
        "\n",
        "    # Visual Comparison\n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.subplot(1,3,1)\n",
        "    sns.barplot(x='Macro Precision', y='Model', data=results_df, palette='coolwarm')\n",
        "    plt.title('Macro Precision Comparison')\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    sns.barplot(x='Macro Recall', y='Model', data=results_df, palette='coolwarm')\n",
        "    plt.title('Macro Recall Comparison')\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    sns.barplot(x='Macro F1', y='Model', data=results_df, palette='coolwarm')\n",
        "    plt.title('Macro F1-Score Comparison')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# Load all trained models (replace paths)\n",
        "models_dict = {\n",
        "    'VGG19': tf.keras.models.load_model('vgg19_best.keras'),\n",
        "    'GoogleNet': tf.keras.models.load_model('googlenet_best.keras'),\n",
        "    'ResNet50': tf.keras.models.load_model('resnet50_best.keras'),\n",
        "    'DenseNet201': tf.keras.models.load_model('densenet_best.keras'),\n",
        "    'EfficientNetV2B1': tf.keras.models.load_model('efficientnet_best.keras')\n",
        "}\n",
        "\n",
        "# Run evaluation\n",
        "results_df = evaluate_all_models(models_dict, test_data)\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv('baseline_models_comparison.csv', index=False)\n",
        "print(\"\\nResults saved to 'baseline_models_comparison.csv'\")"
      ],
      "metadata": {
        "id": "Dkl1FVUyFAcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection"
      ],
      "metadata": {
        "id": "QIIG73JQDVvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FPN-Enhanced EfficientNetV2-B1 Model Construction\n",
        "from tensorflow.keras.layers import Conv2D, UpSampling2D, Concatenate, Input, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_fpn_efficientnet():\n",
        "    # Input Layer\n",
        "    input_tensor = Input(shape=(240, 240, 3))  # Slightly larger than 224 for FPN\n",
        "\n",
        "    # Base Model (EfficientNetV2-B1)\n",
        "    base_model = EfficientNetV2B1(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_tensor=input_tensor\n",
        "    )\n",
        "\n",
        "    # Freeze first 75% layers\n",
        "    for layer in base_model.layers[:int(len(base_model.layers)*0.75)]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Feature Extraction at Different Scales\n",
        "    c2 = base_model.get_layer('block2d_add').output  # 120x120\n",
        "    c3 = base_model.get_layer('block3d_add').output  # 60x60\n",
        "    c4 = base_model.get_layer('block5d_add').output  # 30x30\n",
        "    c5 = base_model.get_layer('top_activation').output  # 15x15\n",
        "\n",
        "    # FPN Top-Down Pathway\n",
        "    # -------------------\n",
        "    # P5 (15x15)\n",
        "    p5 = Conv2D(256, (1, 1), padding='same', name='fpn_c5p5')(c5)\n",
        "\n",
        "    # P4 (30x30)\n",
        "    p5_upsampled = UpSampling2D(size=(2, 2), interpolation='bilinear')(p5)\n",
        "    p4 = Conv2D(256, (1, 1), padding='same', name='fpn_c4p4')(c4)\n",
        "    p4 = Concatenate(axis=-1)([p5_upsampled, p4])\n",
        "    p4 = Conv2D(256, (3, 3), padding='same', name='fpn_p4')(p4)\n",
        "    p4 = BatchNormalization()(p4)\n",
        "\n",
        "    # P3 (60x60)\n",
        "    p4_upsampled = UpSampling2D(size=(2, 2), interpolation='bilinear')(p4)\n",
        "    p3 = Conv2D(256, (1, 1), padding='same', name='fpn_c3p3')(c3)\n",
        "    p3 = Concatenate(axis=-1)([p4_upsampled, p3])\n",
        "    p3 = Conv2D(256, (3, 3), padding='same', name='fpn_p3')(p3)\n",
        "    p3 = BatchNormalization()(p3)\n",
        "\n",
        "    # P2 (120x120)\n",
        "    p3_upsampled = UpSampling2D(size=(2, 2), interpolation='bilinear')(p3)\n",
        "    p2 = Conv2D(256, (1, 1), padding='same', name='fpn_c2p2')(c2)\n",
        "    p2 = Concatenate(axis=-1)([p3_upsampled, p2])\n",
        "    p2 = Conv2D(256, (3, 3), padding='same', name='fpn_p2')(p2)\n",
        "    p2 = BatchNormalization()(p2)\n",
        "\n",
        "    # Feature Fusion\n",
        "    # --------------\n",
        "    # Upsample all features to 60x60 (mid-scale)\n",
        "    p2_up = UpSampling2D(size=(4, 4), interpolation='bilinear')(p2)\n",
        "    p3_up = p3  # Already at 60x60\n",
        "    p4_down = Conv2D(256, (3, 3), strides=2, padding='same')(p4)\n",
        "    p5_down = Conv2D(256, (3, 3), strides=4, padding='same')(p5)\n",
        "\n",
        "    fused = Concatenate(axis=-1)([p2_up, p3_up, p4_down, p5_down])\n",
        "    fused = Conv2D(512, (1, 1), activation='relu')(fused)\n",
        "\n",
        "    # Classification Head\n",
        "    # ------------------\n",
        "    x = GlobalAveragePooling2D()(fused)\n",
        "    x = Dense(512, activation=None)(x)  # Linear before LRe+SigELU\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Custom LRe+SigELU Activation\n",
        "    def lre_sigelu(x):\n",
        "        from tensorflow.keras import backend as K\n",
        "        # Trainable parameters\n",
        "        w1 = 0.6  # ReLU weight (initial)\n",
        "        w2 = 0.4   # SigELU weight (initial)\n",
        "        beta = 1.0  # Sigmoid sharpness\n",
        "        alpha = 1.0 # ELU scale\n",
        "\n",
        "        # ReLU component\n",
        "        relu = w1 * K.relu(x)\n",
        "\n",
        "        # SigELU component\n",
        "        sig = K.sigmoid(beta * x)\n",
        "        elu = alpha * (K.exp(x) - 1) * K.cast(x <= 0, 'float32')  # ELU negative part\n",
        "        sigelu = w2 * sig * elu\n",
        "\n",
        "        return relu + sigelu\n",
        "\n",
        "    x = tf.keras.layers.Activation(lre_sigelu)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(11, activation='softmax')(x)\n",
        "\n",
        "    # Compile Model\n",
        "    model = Model(inputs=input_tensor, outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0005),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', Precision(name='precision'), Recall(name='recall')]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build and Save Model\n",
        "fpn_model = build_fpn_efficientnet()\n",
        "fpn_model.summary()\n",
        "\n",
        "# Save in .keras format\n",
        "fpn_model.save('fpn_efficientnetv2b1.keras', save_format='keras')\n",
        "print(\"Model saved as 'fpn_efficientnetv2b1.keras'\")"
      ],
      "metadata": {
        "id": "7TLypmaDDULq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Post-Training Model Evaluation Metrics\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "def evaluate_model(model, test_data):\n",
        "    \"\"\"\n",
        "    Comprehensive evaluation of a trained model\n",
        "    Args:\n",
        "        model: Trained Keras model\n",
        "        test_data: Test data generator (with shuffle=False)\n",
        "    \"\"\"\n",
        "    # 1. Get predictions and true labels\n",
        "    y_true = test_data.classes\n",
        "    y_pred = model.predict(test_data)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # 2. Classification Report\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Detailed Classification Report\")\n",
        "    print(\"=\"*60)\n",
        "    class_names = list(test_data.class_indices.keys())\n",
        "    report = classification_report(y_true, y_pred_classes, target_names=class_names, digits=4)\n",
        "    print(report)\n",
        "\n",
        "    # 3. Confusion Matrix\n",
        "    plt.figure(figsize=(12,10))\n",
        "    cm = confusion_matrix(y_true, y_pred_classes)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names,\n",
        "                yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix', fontsize=14)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.show()\n",
        "\n",
        "    # 4. Precision-Recall Curve (Micro-average)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    # Convert to binary class indicators for multi-class\n",
        "    y_true_bin = tf.keras.utils.to_categorical(y_true, num_classes=len(class_names))\n",
        "    precision = dict()\n",
        "    recall = dict()\n",
        "    thresholds = dict()\n",
        "\n",
        "    for i in range(len(class_names)):\n",
        "        precision[i], recall[i], thresholds[i] = precision_recall_curve(\n",
        "            y_true_bin[:, i], y_pred[:, i])\n",
        "        plt.plot(recall[i], precision[i], lw=2, label=f'{class_names[i]}')\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve (Per Class)')\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # 5. F1-Score Analysis\n",
        "    f1_per_class = f1_score(y_true, y_pred_classes, average=None)\n",
        "    f1_df = pd.DataFrame({\n",
        "        'Class': class_names,\n",
        "        'F1-Score': f1_per_class\n",
        "    }).sort_values('F1-Score', ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(10,6))\n",
        "    sns.barplot(x='F1-Score', y='Class', data=f1_df, palette='viridis')\n",
        "    plt.title('F1-Scores by Class')\n",
        "    plt.xlim(0, 1)\n",
        "    plt.show()\n",
        "\n",
        "    # 6. Macro/Micro Averages\n",
        "    macro_precision = precision_score(y_true, y_pred_classes, average='macro')\n",
        "    macro_recall = recall_score(y_true, y_pred_classes, average='macro')\n",
        "    macro_f1 = f1_score(y_true, y_pred_classes, average='macro')\n",
        "\n",
        "    micro_precision = precision_score(y_true, y_pred_classes, average='micro')\n",
        "    micro_recall = recall_score(y_true, y_pred_classes, average='micro')\n",
        "    micro_f1 = f1_score(y_true, y_pred_classes, average='micro')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Aggregate Metrics Summary\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Macro Precision: {macro_precision:.4f}\")\n",
        "    print(f\"Macro Recall: {macro_recall:.4f}\")\n",
        "    print(f\"Macro F1-Score: {macro_f1:.4f}\\n\")\n",
        "    print(f\"Micro Precision: {micro_precision:.4f}\")\n",
        "    print(f\"Micro Recall: {micro_recall:.4f}\")\n",
        "    print(f\"Micro F1-Score: {micro_f1:.4f}\")\n",
        "\n",
        "    # 7. Worst Performing Classes\n",
        "    worst_classes = f1_df.tail(3)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"3 Worst Performing Classes\")\n",
        "    print(\"=\"*60)\n",
        "    print(worst_classes.to_string(index=False))\n",
        "\n",
        "# Load your trained model (replace with actual path)\n",
        "model = tf.keras.models.load_model('fpn_efficientnetv2b1.keras')\n",
        "\n",
        "# Ensure test_data is your test generator (with shuffle=False)\n",
        "evaluate_model(model, test_data)"
      ],
      "metadata": {
        "id": "q_sHOmjMEpzV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}